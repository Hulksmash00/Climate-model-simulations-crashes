{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Climate Model Simulation Crashes Data Set </center>\n",
    "\n",
    "**<center>Submitted By:</center>**\n",
    "<center>\n",
    "Name: Kumar Aditya\n",
    "\n",
    "Reg. No.: 12014047\n",
    "</center>\n",
    "# Using 3 classifiers to predict the crash of climate model simulations\n",
    "\n",
    "- LinearRegression\n",
    "- SVR\n",
    "- KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the libraries\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "print(\"Importing the libraries\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Preprocessing\\n\")\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat', sep='\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "Y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data into training and testing sets\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting the data into training and testing sets\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying 3 classifiers to predict the crash of climate model simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "Linear Regression R-squared score = 2.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear regression\")\n",
    "# Define the pipeline steps\n",
    "scaler = StandardScaler() # Standardize the features\n",
    "pca = PCA(n_components=9) # Reduce the dimensionality with PCA\n",
    "reg = LinearRegression() # Fit a linear regression model\n",
    "\n",
    "# Create the pipeline object\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"reg\", reg)])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_reg = pipe.predict(X_test)\n",
    "print(\"Linear Regression R-squared score =\", round(sm.r2_score(y_test, y_pred_reg), 2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Regression\n",
      "SVM R-squared score = -5.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSupport Vector Regression\")\n",
    "# Define the pipeline steps\n",
    "scaler = StandardScaler() # Standardize the features\n",
    "pca = PCA(n_components=9) # Reduce the dimensionality with PCA\n",
    "svr = SVR(kernel=\"rbf\", C=1) # Fit a SVM model\n",
    "\n",
    "# Create the pipeline object\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"svr\", svr)])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svr = pipe.predict(X_test)\n",
    "print(\"SVM R-squared score =\", round(sm.r2_score(y_test, y_pred_svr), 2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors Regression\n",
      "KNN R-squared score = -10.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nK-Nearest Neighbors Regression\")\n",
    "# Define the pipeline steps\n",
    "scaler = StandardScaler() # Standardize the features\n",
    "pca = PCA(n_components=9) # Reduce the dimensionality with PCA\n",
    "knn = KNeighborsRegressor(n_neighbors=5, metric=\"euclidean\") # Fit a KNN model\n",
    "\n",
    "# Create the pipeline object\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"knn\", knn)])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_knn = pipe.predict(X_test)\n",
    "print(\"KNN R-squared score =\", round(sm.r2_score(y_test, y_pred_knn), 2)*100,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the results of the 3 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "Best Model:  Linear Regression\n",
      "Accuracy Score: 2.45%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if sm.r2_score(y_test, y_pred_reg) > sm.r2_score(y_test, y_pred_svr) and sm.r2_score(y_test, y_pred_reg) > sm.r2_score(y_test, y_pred_knn):\n",
    "    best_model = \"Linear Regression\"\n",
    "    best_score = sm.r2_score(y_test, y_pred_reg)\n",
    "elif sm.r2_score(y_test, y_pred_svr) > sm.r2_score(y_test, y_pred_reg) and sm.r2_score(y_test, y_pred_svr) > sm.r2_score(y_test, y_pred_knn):\n",
    "    best_model = \"SVM\"\n",
    "    best_score = sm.r2_score(y_test, y_pred_svr)\n",
    "else:\n",
    "    best_model = \"KNN\"\n",
    "    best_score = sm.r2_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"Best Model: \", best_model)\n",
    "print(\"Accuracy Score: {:.2f}%\".format(best_score*100))\n",
    "print(\"-\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
